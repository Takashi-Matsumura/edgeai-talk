# EdgeAI Talk - よくある質問（FAQ）

## 基本的な質問

### Q1: EdgeAI Talkとは何ですか？

EdgeAI Talkは、ローカルで動作する音声対話型のAIチャットアプリケーションです。インターネット接続不要で、プライバシーを完全に守りながらAIと対話できます。

### Q2: どのようなデバイスで動作しますか？

以下のデバイスで動作します：

- **推奨**: iPad mini 6（縦型レイアウト最適化）
- **対応**: iPhone、Android、デスクトップブラウザ
- **要件**: HTTPS接続が必要（音声認識のため）

### Q3: オフラインで使えますか？

はい、完全にオフラインで動作します。すべての処理はローカルデバイスで実行されます。

---

## 機能について

### Q4: どのような機能がありますか？

主な機能は以下の通りです：

- **音声入力**: タップ&ホールドで音声入力
- **テキスト入力**: キーボードでメッセージ入力
- **音声読み上げ**: VOICEVOXによるずんだもんの声
- **リアルタイムストリーミング応答**: AIが考えながらリアルタイムで応答
- **会話履歴の保存**: 過去の会話を記録
- **PWA対応**: ホーム画面に追加可能

### Q5: 音声認識の精度は？

Web Speech APIを使用しており、日本語の認識精度は約95%です。静かな環境での使用を推奨します。

### Q6: どのような質問に答えられますか？

LM Studioで読み込んだモデルの能力に依存します。一般的な質問、プログラミング、日常会話など幅広く対応できます。

### Q7: RAG（知識検索）機能とは何ですか？

展示会の他ブース情報など、カスタム情報をAIに学習させることができる機能です。ドキュメントをアップロードすることで、AIがその内容について正確に回答できるようになります。

---

## 技術的な質問

### Q8: 使用している技術スタックは？

- **フロントエンド**: Next.js 15, React 19, TypeScript
- **LLM**: LM Studio（OpenAI互換API）
- **音声**: Web Speech API, VOICEVOX
- **スタイリング**: Tailwind CSS v4
- **RAG**: ChromaDB, FastAPI

### Q9: LM Studioのセットアップ方法は？

1. LM Studioをダウンロード・インストール
2. モデル（例: gemma-3n-e4b）をロード
3. ローカルサーバーを起動（ポート1234）
4. EdgeAI Talkを起動

### Q10: HTTPS証明書のエラーが出ます

自己署名証明書を使用しているため、初回アクセス時にブラウザで警告が表示されます。「詳細設定」→「アクセスする」で承認してください。

---

## トラブルシューティング

### Q11: 音声入力が動作しません

以下を確認してください：

- HTTPS接続を使用しているか
- マイク許可を承認したか
- 音声モードがONになっているか
- デバイスのマイクが正常に動作しているか

### Q12: 音声読み上げが動作しません

- VOICEVOXコンテナが起動しているか確認
- 起動していない場合は自動的にブラウザTTSにフォールバック
- `docker-compose up -d voicevox` で起動可能

### Q13: レスポンスが遅いです

- LM Studioでより小さいモデルを試す
- GPUアクセラレーションが有効か確認
- システムリソース（CPU/メモリ）を確認
- 推奨モデル（gemma-3n-e4b）を使用

### Q14: ずんだもんの動画が表示されません

動画の読み込みに失敗した場合は、自動的に絵文字アイコンで代替表示されます。これは正常な動作で、機能には影響ありません。

---

## セキュリティとプライバシー

### Q15: データはどこに保存されますか？

すべてのデータはローカルデバイスに保存されます。外部サーバーへの送信は一切ありません。

### Q16: 会話内容は記録されますか？

ブラウザのメモリにのみ保存され、ページをリロードすると消去されます。永続化する場合は、会話履歴をコピーして保存してください。

### Q17: インターネット接続は必要ですか？

いいえ、一切必要ありません。すべての処理がローカルで完結するため、インターネット接続なしで動作します。

### Q18: どのような情報が外部に送信されますか？

何も送信されません。音声認識、AI処理、音声合成、すべての機能がローカルで完結しています。

---

## その他

### Q19: 商用利用は可能ですか？

MITライセンスで提供されていますが、使用するLLMモデルのライセンスを確認してください。

### Q20: カスタマイズは可能ですか？

はい、オープンソースプロジェクトなので自由にカスタマイズできます。

### Q21: サポートはありますか？

GitHubリポジトリのIssuesでサポートを提供しています。

### Q22: モバイルデバイスでの操作方法は？

- **音声入力**: 左下のずんだもんアイコンをタップ&ホールド
- **音声停止**: 右下のずんだもんアイコンをタップ
- **テキスト入力**: 画面下部の入力欄を使用
- **設定変更**: 右上のメニューから各種設定を変更

### Q23: 推奨される使用環境は？

- **デバイス**: iPad mini 6以上
- **ネットワーク**: ローカルネットワーク接続
- **環境**: 静かな室内（音声認識精度向上のため）
- **ブラウザ**: Safari（iOS）、Chrome（Android）

### Q24: システムの応答速度はどのくらいですか？

標準的な環境では以下の速度で動作します：

- **音声認識**: 1-2秒
- **AI初回応答**: 0.5-1秒
- **ストリーミング応答**: 20-30トークン/秒
- **音声合成**: 100-200ms

実際の速度は、使用するデバイスの性能とLLMモデルのサイズによって変動します。
