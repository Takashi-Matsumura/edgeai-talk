# EdgeAI Talk - 技術仕様

## システム概要

EdgeAI Talkは、インターネット接続なしで動作する完全オフライン対応のAI対話システムです。すべての処理がローカルデバイスで完結し、プライバシーを完全に保護します。

---

## 1. 動作環境

### サーバー側（ホストマシン）

- **OS**: macOS 12+, Ubuntu 20.04+, Windows 10/11
- **CPU**: 4コア以上推奨
- **RAM**: 8GB以上（16GB推奨）
- **ストレージ**: 10GB以上の空き容量
- **Node.js**: v20以降
- **Docker**: v20.10以降（VOICEVOX使用時）
- **Python**: v3.11以降（RAG機能使用時）

### クライアント側（タブレット・スマートフォン）

- **対応ブラウザ**:
  - Safari 14+（iOS/iPadOS）
  - Chrome 90+
  - Edge 90+
  - Firefox 88+
- **ネットワーク**: ローカルネットワーク接続のみ（オフライン動作可能）

---

## 2. AIモデル仕様

### 推奨モデル

- **Google Gemma 3N E4B** (3Bパラメータ)
  - 量子化: 4-bit
  - メモリ使用量: 約2GB
  - 推論速度: 約20トークン/秒（M1 Max使用時）

### その他の対応モデル

- **Llama 3.2** (1B, 3Bパラメータ)
- **Phi 3 Mini**
- **Qwen 2.5** (0.5B, 1.5B, 3Bパラメータ）

### モデル要件

- OpenAI互換API対応
- コンテキスト長: 2048トークン以上
- ストリーミング応答対応

---

## 3. API仕様

### LM Studio API

- **エンドポイント**: `http://localhost:1234`
- **プロトコル**: HTTP/1.1
- **応答形式**: Server-Sent Events (SSE)
- **タイムアウト**: 120秒

### VOICEVOX API

- **エンドポイント**: `http://localhost:50021`
- **話者**: ずんだもん（Speaker ID: 3, ノーマルモード）
- **音声形式**: WAV (PCM, 24kHz, 16bit)
- **処理時間**: 約100-200ms

### RAG Backend API

- **エンドポイント**: `http://localhost:8000`
- **ベクトルDB**: ChromaDB
- **埋め込みモデル**: intfloat/multilingual-e5-base
- **ベクトル次元**: 768
- **類似度閾値**: 0.5以上

---

## 4. ネットワーク構成

### ポート番号

- **3000**: Next.js アプリケーション（HTTPS）
- **1234**: LM Studio API
- **8000**: RAG Backend (FastAPI)
- **50021**: VOICEVOX Engine

### 通信プロトコル

- **Frontend ⇔ Next.js**: HTTPS (TLS 1.3)
- **Next.js ⇔ LM Studio**: HTTP
- **Next.js ⇔ RAG Backend**: HTTP
- **Next.js ⇔ VOICEVOX**: HTTP

### セキュア通信

- **証明書**: 自己署名証明書（開発用）
- **暗号化**: RSA 4096-bit
- **有効期限**: 365日

---

## 5. パフォーマンス指標

### 応答時間

- **音声認識**: 1-2秒（Web Speech APIに依存）
- **AI初回応答**: 0.5-1秒
- **AIストリーミング応答**: 20-30トークン/秒
- **音声合成**: 100-200ms

### リソース使用量

- **Next.js プロセス**: 100-200MB
- **LM Studio**: 2-4GB（モデルに依存）
- **ChromaDB**: 100-500MB（データ量に依存）
- **VOICEVOX**: 200-400MB

### 処理能力

- **同時接続数**: 最大10セッション（開発環境）
- **最大メッセージ長**: 2000文字
- **会話履歴保持**: 最大50メッセージ

---

## 6. セキュリティとプライバシー

### データ保護

- **完全ローカル処理**: すべてのAI処理がローカルで実行
- **外部送信ゼロ**: インターネット経由のデータ送信なし
- **プライバシー保護**: 会話内容はデバイス内のみに保存

### 認証・アクセス制御

- **現バージョン**: 認証なし（ローカル専用のため）
- **将来バージョン**: Basic認証対応予定

### セキュア通信

- **HTTPS必須**: 音声認識APIの要件により必須
- **自己署名証明書**: 開発環境で使用
- **本番環境**: 正式な証明書使用を推奨

---

## 7. ログとモニタリング

### ログレベル

- **INFO**: 通常動作の記録
- **WARN**: 警告（フォールバック時など）
- **ERROR**: エラー発生時

### ログ出力先

- **Next.js**: stdout
- **LM Studio**: アプリケーション内部ログ
- **VOICEVOX**: Dockerログ
- **RAG Backend**: stdout/stderr

### 監視項目

- **API応答時間**: 各APIの処理速度
- **エラー率**: システムの安定性
- **メモリ使用量**: リソース使用状況
- **CPU使用率**: プロセッサー負荷

---

## システムの特徴

### プライバシー第一

会話内容、音声データ、すべての処理がローカルデバイス内で完結します。インターネット経由でデータが外部に送信されることは一切ありません。

### 高速レスポンス

エッジコンピューティング技術により、クラウドサービスと比較して高速な応答を実現しています。

### オフライン動作

インターネット接続が不要なため、ネットワーク環境に左右されず、いつでもどこでも利用できます。

### 拡張性

RAG機能により、展示会の他ブース情報など、カスタム情報を追加してAIに学習させることができます。
